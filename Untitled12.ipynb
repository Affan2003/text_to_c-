{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S1OVW4c5mW02",
        "outputId": "870be9ce-7312-4f48-caec-03ffc213264c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (0.2.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(\n",
            "Epoch 1: 100%|██████████| 6758/6758 [11:00<00:00, 10.23it/s, loss=0.341]\n",
            "Epoch 2: 100%|██████████| 6758/6758 [10:53<00:00, 10.34it/s, loss=0.299]\n",
            "Epoch 3: 100%|██████████| 6758/6758 [10:56<00:00, 10.29it/s, loss=0.135]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated C++ Code:\n",
            " my  G0; mmendend[12]\n"
          ]
        }
      ],
      "source": [
        "# Install required libraries\n",
        "!pip install sentencepiece torch tqdm pandas\n",
        "\n",
        "# Import libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import sentencepiece as spm\n",
        "import pandas as pd\n",
        "import os\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Enable detailed CUDA error messages\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
        "\n",
        "# Load Dataset\n",
        "df = pd.read_csv(\"spoc-train.csv\")\n",
        "df = df.dropna()\n",
        "\n",
        "# Save pseudocode & C++ pairs for tokenizer training\n",
        "pseudo_file = \"pseudocode.txt\"\n",
        "cpp_file = \"cpp.txt\"\n",
        "df[\"text\"].to_csv(pseudo_file, index=False, header=False)\n",
        "df[\"code\"].to_csv(cpp_file, index=False, header=False)\n",
        "\n",
        "# Train BPE Tokenizer\n",
        "vocab_size = 10000\n",
        "spm.SentencePieceTrainer.train(input=f\"{pseudo_file},{cpp_file}\", model_prefix=\"bpe\", vocab_size=vocab_size)\n",
        "\n",
        "# Load Tokenizer\n",
        "sp = spm.SentencePieceProcessor()\n",
        "sp.load(\"bpe.model\")\n",
        "\n",
        "# Dataset Class\n",
        "class CodeDataset(Dataset):\n",
        "    def __init__(self, df, tokenizer):\n",
        "        self.data = df\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        pseudo = self.data.iloc[idx][\"text\"]\n",
        "        cpp = self.data.iloc[idx][\"code\"]\n",
        "        pseudo_ids = self.tokenizer.encode(pseudo, out_type=int)\n",
        "        cpp_ids = self.tokenizer.encode(cpp, out_type=int)\n",
        "        return torch.tensor(pseudo_ids), torch.tensor(cpp_ids)\n",
        "\n",
        "# Create DataLoader\n",
        "dataset = CodeDataset(df, sp)\n",
        "dataloader = DataLoader(dataset, batch_size=32, shuffle=True, collate_fn=lambda x: x)\n",
        "\n",
        "# Transformer Model\n",
        "class TransformerModel(nn.Module):\n",
        "    def __init__(self, vocab_size, d_model=256, nhead=8, num_layers=6):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
        "        self.transformer = nn.Transformer(d_model=d_model, nhead=nhead, num_encoder_layers=num_layers, num_decoder_layers=num_layers)\n",
        "        self.fc_out = nn.Linear(d_model, vocab_size)\n",
        "\n",
        "    def forward(self, src, tgt):\n",
        "        src = self.embedding(src).permute(1, 0, 2)\n",
        "        tgt = self.embedding(tgt).permute(1, 0, 2)\n",
        "        output = self.transformer(src, tgt)\n",
        "        return self.fc_out(output).permute(1, 0, 2)\n",
        "\n",
        "# Training Setup\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "vocab_size = 10000\n",
        "model = TransformerModel(vocab_size).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=2e-4)\n",
        "\n",
        "def train_model(model, dataloader, epochs=3):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        loop = tqdm(dataloader, desc=f\"Epoch {epoch+1}\")\n",
        "        for batch in loop:\n",
        "            pseudo_batch, cpp_batch = zip(*batch)\n",
        "            pseudo_batch = nn.utils.rnn.pad_sequence(pseudo_batch, batch_first=True).long().to(device)\n",
        "            cpp_batch = nn.utils.rnn.pad_sequence(cpp_batch, batch_first=True).long().to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            output = model(pseudo_batch, cpp_batch[:, :-1])\n",
        "            loss = criterion(output.reshape(-1, vocab_size), cpp_batch[:, 1:].reshape(-1))\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            loop.set_postfix(loss=loss.item())\n",
        "\n",
        "train_model(model, dataloader)\n",
        "\n",
        "# Save Model & Tokenizer\n",
        "torch.save(model.state_dict(), \"transformer_model.pth\")\n",
        "\n",
        "# Save the tokenizer model\n",
        "with open(\"bpe.model\", \"wb\") as f:\n",
        "    f.write(sp.serialized_model_proto())\n",
        "\n",
        "# Testing\n",
        "def generate(model, tokenizer, pseudo):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        pseudo_ids = tokenizer.encode(pseudo, out_type=int)\n",
        "        pseudo_tensor = torch.tensor(pseudo_ids).unsqueeze(0).to(device)\n",
        "        output = model(pseudo_tensor, pseudo_tensor)\n",
        "        predicted_ids = torch.argmax(output, dim=-1).squeeze().tolist()\n",
        "        return tokenizer.decode(predicted_ids)\n",
        "\n",
        "sample_pseudo = \"Sort the array using quicksort\"\n",
        "predicted_cpp = generate(model, sp, sample_pseudo)\n",
        "print(\"Generated C++ Code:\\n\", predicted_cpp)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_pseudo = \"create n\"\n",
        "predicted_cpp = generate(model, sp, sample_pseudo)\n",
        "print(\"Generated C++ Code:\\n\", predicted_cpp)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pm96JkJImaYf",
        "outputId": "a74bd53b-b1fb-4b23-9ef3-537d57f883ac"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated C++ Code:\n",
            " nma\n"
          ]
        }
      ]
    }
  ]
}